{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78efb730",
   "metadata": {},
   "source": [
    "# Customizing SageMaker PyTorch Framework Container\n",
    "\n",
    "SageMaker Framework containers support installing dependencies from a `requirements.txt` file submitted with your scripts: But this might not be desirable if:\n",
    "\n",
    "- You re-use the same set of dependencies very often in many jobs (since the pip install happens on billable instance time), or\n",
    "- You want to disable network access and control which packages are available in the environment.\n",
    "\n",
    "While you could build [fully custom containers](https://github.com/aws/amazon-sagemaker-examples/tree/master/advanced_functionality/custom-training-containers) and even implement the same \"framework\" pattern in your own images, if the goal is just to add a few libraries on top of the SageMaker provided base - there's no reason to re-invent the wheel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d771f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import os\n",
    "import shutil\n",
    "from string import Template\n",
    "import subprocess\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "botosess = boto3.Session()\n",
    "account_id = botosess.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = botosess.region_name\n",
    "smsess = sagemaker.Session(boto_session=botosess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e5531",
   "metadata": {},
   "source": [
    "## Get parent AWS images\n",
    "\n",
    "For simple library customizations, we'll just derive containers `FROM` the SageMaker-maintained framework images for CPU (set by `instance_type`) training and inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e973ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_uri(scope=\"training\", instance_type=\"ml.m5.large\"):\n",
    "    return sagemaker.image_uris.retrieve(\n",
    "        \"pytorch\",\n",
    "        region=botosess.region_name,\n",
    "        version=\"1.7\",\n",
    "        py_version=\"py3\",\n",
    "        instance_type=instance_type,\n",
    "        accelerator_type=None,\n",
    "        image_scope=scope,\n",
    "        container_version=None,\n",
    "        #distribution=None,\n",
    "        #base_framework_version=None,\n",
    "    )\n",
    "\n",
    "train_parent_uri = get_image_uri(scope=\"training\", instance_type=\"ml.m5.large\")\n",
    "print(f\"Training: {train_parent_uri}\")\n",
    "inf_parent_uri = get_image_uri(scope=\"inference\", instance_type=\"ml.m5.large\")\n",
    "print(f\"Serving: {inf_parent_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54477787",
   "metadata": {},
   "source": [
    "## Common setup\n",
    "\n",
    "This docker template assumes and uses a requirements.txt - so we'll just copy in the one from the `src/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy2(\"src/requirements.txt\", \"container/requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ac690",
   "metadata": {},
   "source": [
    "Log in to ECR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8619814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our account:\n",
    "print(f\"Logging in to our account {account_id} ({region})...\")\n",
    "our_docker_registry = f\"{account_id}.dkr.ecr.{region}.amazonaws.com\"\n",
    "!aws ecr get-login-password | docker login --username AWS --password-stdin $our_docker_registry\n",
    "# Training & inference are always in same account I think:\n",
    "print(f\"Logging in to {train_parent_uri})\")\n",
    "parent_docker_registry = train_parent_uri.partition(\"/\")[0]\n",
    "!aws ecr get-login-password | docker login --username AWS --password-stdin $parent_docker_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8164a",
   "metadata": {},
   "source": [
    "Create the ECR repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo_name = \"sagemaker-custom\"\n",
    "our_docker_repo_uri = f\"{our_docker_registry}/{docker_repo_name}\"\n",
    "\n",
    "!aws ecr create-repository --repository-name $docker_repo_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531b8d9",
   "metadata": {},
   "source": [
    "## Build images\n",
    "\n",
    "The provided template Dockerfile `Dockerfile.tpl` inherits `FROM` some base image and simply installs the contents of requirements.txt... So we'll build separate custom images for training and inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c14415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dockerfile(parent):\n",
    "    with open(\"container/Dockerfile.tpl\", \"r\") as ftmp:\n",
    "        docker_template = Template(ftmp.read())\n",
    "        with open(\"container/Dockerfile\", \"w\") as fdocker:\n",
    "            fdocker.write(docker_template.substitute({\n",
    "                \"BASE_IMAGE\": parent,\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f34712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build training:\n",
    "custom_training_uri = f\"{our_docker_repo_uri}:training-latest\"\n",
    "init_dockerfile(train_parent_uri)\n",
    "!cd container && docker build -t custom-pytorch-training -t $custom_training_uri ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef822472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build inference:\n",
    "custom_inference_uri = f\"{our_docker_repo_uri}:inference-latest\"\n",
    "init_dockerfile(inf_parent_uri)\n",
    "!cd container && docker build -t custom-pytorch-inference -t $custom_inference_uri ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b129ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c0a50",
   "metadata": {},
   "source": [
    "## Push containers to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acacbb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Pushing to {custom_training_uri}\")\n",
    "!docker push $custom_training_uri\n",
    "%store custom_training_uri\n",
    "\n",
    "print(f\"Pushing to {custom_inference_uri}\")\n",
    "!docker push $custom_inference_uri\n",
    "%store custom_inference_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1413e25",
   "metadata": {},
   "source": [
    "Our customized training and inference container URIs should now be ready to use!\n",
    "\n",
    "Use e.g. via the `image_uri` override parameters in [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Estimator) and [Model](https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model) constructors (inherited by e.g. `PyTorch` and `PyTorchModel`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
