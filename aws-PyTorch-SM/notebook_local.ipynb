{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67749d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "## sequence \n",
    "import itertools\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "## train module \n",
    "import gzip\n",
    "import pickle\n",
    "import datetime\n",
    "import itertools\n",
    "\n",
    "from typing import Any\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865190b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-PyTorch  aws-PyTorch.zip  lost+found  Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls ./aws-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ec3f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:628\n"
     ]
    }
   ],
   "source": [
    "#load sequnece data\n",
    "# data_path = '/Users/md.kamal/work-code-sample/location-recommendation/notebooks'\n",
    "\n",
    "with open(\"data/list_seq.pickle\", 'rb') as f:\n",
    "    list_seq = pickle.load(f)\n",
    "\n",
    "with open(\"data/dict_loc.pickle\", 'rb') as f:\n",
    "    dict_loc = pickle.load(f)\n",
    "\n",
    "loc2idx = {w: idx for (idx, w) in enumerate(dict_loc)}\n",
    "idx2loc = {idx: w for (idx, w) in enumerate(dict_loc)}\n",
    "vocab_size = len(dict_loc)\n",
    "print(f\"vocab_size:{vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532a17d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mycty_51510': 0,\n",
       " 'mycty_51931': 1,\n",
       " 'mysta_41683': 2,\n",
       " 'mycty_51919': 3,\n",
       " 'mycty_51482': 4,\n",
       " 'mycty_52007': 5,\n",
       " 'mycty_51547': 6,\n",
       " 'mycty_51475': 7,\n",
       " 'mycty_52028': 8,\n",
       " 'mycty_51417': 9,\n",
       " 'mycty_51407': 10,\n",
       " 'mycty_51387': 11,\n",
       " 'mycty_51675': 12,\n",
       " 'mycty_51997': 13,\n",
       " 'mycty_51451': 14,\n",
       " 'mycty_51980': 15,\n",
       " 'mycty_51661': 16,\n",
       " 'mycty_51668': 17,\n",
       " 'mycty_52037': 18,\n",
       " 'mysta_25733': 19,\n",
       " 'mycty_51917': 20,\n",
       " 'mycty_51823': 21,\n",
       " 'mycty_52011': 22,\n",
       " 'mycty_51795': 23,\n",
       " 'mycty_51908': 24,\n",
       " 'mycty_51913': 25,\n",
       " 'mycty_51549': 26,\n",
       " 'mycty_51386': 27,\n",
       " 'mycty_51884': 28,\n",
       " 'mycty_51534': 29,\n",
       " 'mycty_51600': 30,\n",
       " 'mycty_51783': 31,\n",
       " 'mycty_51894': 32,\n",
       " 'mycty_51848': 33,\n",
       " 'mycty_51930': 34,\n",
       " 'mycty_51679': 35,\n",
       " 'mycty_51969': 36,\n",
       " 'mycty_52005': 37,\n",
       " 'mycty_51527': 38,\n",
       " 'mycty_51841': 39,\n",
       " 'mycty_51592': 40,\n",
       " 'mycty_51526': 41,\n",
       " 'mycty_51857': 42,\n",
       " 'mycty_51806': 43,\n",
       " 'mycty_52052': 44,\n",
       " 'mycty_51793': 45,\n",
       " 'mycty_52055': 46,\n",
       " 'mycty_51822': 47,\n",
       " 'mycty_51639': 48,\n",
       " 'mycty_51585': 49,\n",
       " 'mycty_51405': 50,\n",
       " 'mycty_51532': 51,\n",
       " 'mycty_51570': 52,\n",
       " 'mycty_51794': 53,\n",
       " 'mycty_51801': 54,\n",
       " 'mycty_51460': 55,\n",
       " 'mycty_51958': 56,\n",
       " 'mycty_51882': 57,\n",
       " 'mycty_52014': 58,\n",
       " 'mycty_51961': 59,\n",
       " 'mycty_51956': 60,\n",
       " 'mycty_51838': 61,\n",
       " 'mycty_51672': 62,\n",
       " 'mycty_51580': 63,\n",
       " 'mycty_51603': 64,\n",
       " 'mycty_51442': 65,\n",
       " 'mycty_51476': 66,\n",
       " 'mycty_51825': 67,\n",
       " 'mycty_51923': 68,\n",
       " 'mycty_51406': 69,\n",
       " 'mycty_51577': 70,\n",
       " 'mycty_51522': 71,\n",
       " 'mycty_51456': 72,\n",
       " 'mycty_51695': 73,\n",
       " 'mycty_51879': 74,\n",
       " 'mycty_52010': 75,\n",
       " 'mycty_51716': 76,\n",
       " 'mycty_51575': 77,\n",
       " 'mycty_51719': 78,\n",
       " 'mycty_51656': 79,\n",
       " 'mycty_51805': 80,\n",
       " 'mycty_51663': 81,\n",
       " 'mycty_51436': 82,\n",
       " 'mycty_51556': 83,\n",
       " 'mycty_51775': 84,\n",
       " 'mycty_51953': 85,\n",
       " 'mycty_51484': 86,\n",
       " 'mycty_51495': 87,\n",
       " 'mycty_51491': 88,\n",
       " 'mycty_51572': 89,\n",
       " 'mycty_51629': 90,\n",
       " 'mycty_51830': 91,\n",
       " 'mycty_51623': 92,\n",
       " 'mycty_52053': 93,\n",
       " 'mycty_51846': 94,\n",
       " 'mycty_51809': 95,\n",
       " 'mycty_51383': 96,\n",
       " 'mycty_51900': 97,\n",
       " 'mycty_51910': 98,\n",
       " 'mycty_51515': 99,\n",
       " 'mycty_51457': 100,\n",
       " 'mycty_51621': 101,\n",
       " 'mycty_51684': 102,\n",
       " 'mycty_52043': 103,\n",
       " 'mycty_51564': 104,\n",
       " 'mycty_51432': 105,\n",
       " 'mycty_51728': 106,\n",
       " 'mycty_51883': 107,\n",
       " 'mycty_51587': 108,\n",
       " 'mycty_51701': 109,\n",
       " 'mycty_51974': 110,\n",
       " 'mycty_51648': 111,\n",
       " 'mycty_51440': 112,\n",
       " 'mycty_51784': 113,\n",
       " 'mycty_51443': 114,\n",
       " 'mycty_51512': 115,\n",
       " 'mycty_51845': 116,\n",
       " 'mycty_51688': 117,\n",
       " 'mycty_51814': 118,\n",
       " 'mysta_15367': 119,\n",
       " 'mycty_51500': 120,\n",
       " 'mycty_51669': 121,\n",
       " 'mycty_51631': 122,\n",
       " 'mycty_51584': 123,\n",
       " 'mycty_51636': 124,\n",
       " 'mycty_51489': 125,\n",
       " 'mycty_51588': 126,\n",
       " 'mycty_51543': 127,\n",
       " 'mycty_51959': 128,\n",
       " 'mycty_51569': 129,\n",
       " 'mycty_51390': 130,\n",
       " 'mycty_52034': 131,\n",
       " 'mycty_51778': 132,\n",
       " 'mycty_51952': 133,\n",
       " 'mycty_51655': 134,\n",
       " 'mycty_51378': 135,\n",
       " 'mycty_51511': 136,\n",
       " 'mycty_51538': 137,\n",
       " 'mycty_51987': 138,\n",
       " 'mycty_51950': 139,\n",
       " 'mycty_51816': 140,\n",
       " 'mycty_51731': 141,\n",
       " 'mycty_51535': 142,\n",
       " 'mycty_51982': 143,\n",
       " 'mycty_51887': 144,\n",
       " 'mycty_51409': 145,\n",
       " 'mycty_51690': 146,\n",
       " 'mycty_51850': 147,\n",
       " 'mycty_51466': 148,\n",
       " 'mycty_51871': 149,\n",
       " 'mycty_52046': 150,\n",
       " 'mycty_51709': 151,\n",
       " 'mycty_51999': 152,\n",
       " 'mycty_51747': 153,\n",
       " 'mycty_51899': 154,\n",
       " 'mycty_51415': 155,\n",
       " 'mycty_51513': 156,\n",
       " 'mycty_51462': 157,\n",
       " 'mycty_51973': 158,\n",
       " 'mycty_52044': 159,\n",
       " 'mycty_51422': 160,\n",
       " 'mycty_51641': 161,\n",
       " 'mycty_51597': 162,\n",
       " 'mycty_51626': 163,\n",
       " 'mycty_51799': 164,\n",
       " 'mycty_51493': 165,\n",
       " 'mycty_51562': 166,\n",
       " 'mycty_51872': 167,\n",
       " 'mycty_51881': 168,\n",
       " 'mycty_51888': 169,\n",
       " 'mycty_51902': 170,\n",
       " 'mycty_51567': 171,\n",
       " 'mycty_51967': 172,\n",
       " 'mycty_52015': 173,\n",
       " 'mycty_51530': 174,\n",
       " 'mycty_51680': 175,\n",
       " 'mycty_51827': 176,\n",
       " 'mycty_51790': 177,\n",
       " 'mycty_51777': 178,\n",
       " 'mycty_51966': 179,\n",
       " 'mycty_51694': 180,\n",
       " 'mycty_51951': 181,\n",
       " 'mycty_51464': 182,\n",
       " 'mycty_51711': 183,\n",
       " 'mycty_51878': 184,\n",
       " 'mycty_51849': 185,\n",
       " 'mycty_51517': 186,\n",
       " 'mycty_51889': 187,\n",
       " 'mycty_52049': 188,\n",
       " 'mycty_51455': 189,\n",
       " 'mycty_51537': 190,\n",
       " 'mycty_51435': 191,\n",
       " 'mycty_51428': 192,\n",
       " 'mycty_51379': 193,\n",
       " 'mycty_51605': 194,\n",
       " 'mycty_51490': 195,\n",
       " 'mycty_51937': 196,\n",
       " 'mycty_51725': 197,\n",
       " 'mycty_52027': 198,\n",
       " 'mycty_51876': 199,\n",
       " 'mycty_52033': 200,\n",
       " 'mycty_51723': 201,\n",
       " 'mycty_51976': 202,\n",
       " 'mycty_51815': 203,\n",
       " 'mycty_51673': 204,\n",
       " 'mycty_51948': 205,\n",
       " 'mycty_51488': 206,\n",
       " 'mycty_51704': 207,\n",
       " 'mycty_51755': 208,\n",
       " 'mycty_51478': 209,\n",
       " 'mycty_51453': 210,\n",
       " 'mycty_52029': 211,\n",
       " 'mycty_51539': 212,\n",
       " 'mycty_51896': 213,\n",
       " 'mycty_51540': 214,\n",
       " 'mycty_51647': 215,\n",
       " 'mycty_51651': 216,\n",
       " 'mycty_51898': 217,\n",
       " 'mycty_51873': 218,\n",
       " 'mycty_51469': 219,\n",
       " 'mycty_51734': 220,\n",
       " 'mycty_51812': 221,\n",
       " 'mycty_51633': 222,\n",
       " 'mycty_51560': 223,\n",
       " 'mycty_51674': 224,\n",
       " 'mycty_51581': 225,\n",
       " 'mycty_51905': 226,\n",
       " 'mycty_51954': 227,\n",
       " 'mycty_51414': 228,\n",
       " 'mycty_51388': 229,\n",
       " 'mycty_51389': 230,\n",
       " 'mycty_51939': 231,\n",
       " 'mycty_51858': 232,\n",
       " 'mycty_52008': 233,\n",
       " 'mycty_51710': 234,\n",
       " 'mycty_51968': 235,\n",
       " 'mycty_51754': 236,\n",
       " 'mycty_52035': 237,\n",
       " 'mycty_51828': 238,\n",
       " 'mycty_51851': 239,\n",
       " 'mycty_51503': 240,\n",
       " 'mycty_51859': 241,\n",
       " 'mycty_51667': 242,\n",
       " 'mycty_51461': 243,\n",
       " 'mycty_51721': 244,\n",
       " 'mycty_51844': 245,\n",
       " 'mycty_51700': 246,\n",
       " 'mycty_51660': 247,\n",
       " 'mycty_52036': 248,\n",
       " 'mycty_51768': 249,\n",
       " 'mycty_51664': 250,\n",
       " 'mycty_51984': 251,\n",
       " 'mycty_51761': 252,\n",
       " 'mycty_51618': 253,\n",
       " 'mycty_51454': 254,\n",
       " 'mycty_51789': 255,\n",
       " 'mycty_51765': 256,\n",
       " 'mycty_51617': 257,\n",
       " 'mycty_51677': 258,\n",
       " 'mycty_51785': 259,\n",
       " 'mycty_51751': 260,\n",
       " 'mycty_51459': 261,\n",
       " 'mycty_51861': 262,\n",
       " 'mycty_51678': 263,\n",
       " 'mycty_51441': 264,\n",
       " 'mycty_51681': 265,\n",
       " 'mycty_51393': 266,\n",
       " 'mycty_52013': 267,\n",
       " 'mycty_51837': 268,\n",
       " 'mycty_52026': 269,\n",
       " 'mycty_51868': 270,\n",
       " 'mycty_51394': 271,\n",
       " 'mycty_51416': 272,\n",
       " 'mycty_51519': 273,\n",
       " 'mycty_51843': 274,\n",
       " 'mycty_51835': 275,\n",
       " 'mycty_51619': 276,\n",
       " 'mycty_51507': 277,\n",
       " 'mycty_51574': 278,\n",
       " 'mycty_51877': 279,\n",
       " 'mycty_51819': 280,\n",
       " 'mycty_51860': 281,\n",
       " 'mycty_51650': 282,\n",
       " 'mycty_51712': 283,\n",
       " 'mycty_51446': 284,\n",
       " 'mycty_51748': 285,\n",
       " 'mycty_51985': 286,\n",
       " 'mycty_51992': 287,\n",
       " 'mycty_52020': 288,\n",
       " 'mycty_51702': 289,\n",
       " 'mycty_51928': 290,\n",
       " 'mycty_51769': 291,\n",
       " 'mycty_51753': 292,\n",
       " 'mycty_51392': 293,\n",
       " 'mycty_51807': 294,\n",
       " 'mycty_51607': 295,\n",
       " 'mycty_51380': 296,\n",
       " 'mycty_51696': 297,\n",
       " 'mycty_51762': 298,\n",
       " 'mycty_51740': 299,\n",
       " 'mycty_51787': 300,\n",
       " 'mycty_52032': 301,\n",
       " 'mycty_51752': 302,\n",
       " 'mycty_51546': 303,\n",
       " 'mycty_51657': 304,\n",
       " 'mycty_51541': 305,\n",
       " 'mycty_51741': 306,\n",
       " 'mycty_51735': 307,\n",
       " 'mycty_51786': 308,\n",
       " 'mycty_51856': 309,\n",
       " 'mycty_51481': 310,\n",
       " 'mycty_51818': 311,\n",
       " 'mycty_52021': 312,\n",
       " 'mycty_51483': 313,\n",
       " 'mycty_51470': 314,\n",
       " 'mycty_51480': 315,\n",
       " 'mycty_51989': 316,\n",
       " 'mycty_51916': 317,\n",
       " 'mycty_52047': 318,\n",
       " 'mycty_51666': 319,\n",
       " 'mycty_51692': 320,\n",
       " 'mycty_51589': 321,\n",
       " 'mycty_52009': 322,\n",
       " 'mycty_51533': 323,\n",
       " 'mycty_51824': 324,\n",
       " 'mycty_51448': 325,\n",
       " 'mycty_51776': 326,\n",
       " 'mycty_51802': 327,\n",
       " 'mycty_51820': 328,\n",
       " 'mycty_51433': 329,\n",
       " 'mycty_51853': 330,\n",
       " 'mycty_51957': 331,\n",
       " 'mycty_51653': 332,\n",
       " 'mycty_51706': 333,\n",
       " 'mycty_51988': 334,\n",
       " 'mycty_51780': 335,\n",
       " 'mycty_51494': 336,\n",
       " 'mycty_51408': 337,\n",
       " 'mycty_51645': 338,\n",
       " 'mycty_51962': 339,\n",
       " 'mycty_51764': 340,\n",
       " 'mycty_51642': 341,\n",
       " 'mycty_51473': 342,\n",
       " 'mycty_51955': 343,\n",
       " 'mycty_51745': 344,\n",
       " 'mycty_52041': 345,\n",
       " 'mycty_51924': 346,\n",
       " 'mycty_51643': 347,\n",
       " 'mycty_51568': 348,\n",
       " 'mycty_51599': 349,\n",
       " 'mycty_51486': 350,\n",
       " 'mycty_51449': 351,\n",
       " 'mycty_51606': 352,\n",
       " 'mycty_51774': 353,\n",
       " 'mycty_51691': 354,\n",
       " 'mycty_51472': 355,\n",
       " 'mycty_51382': 356,\n",
       " 'mycty_51885': 357,\n",
       " 'mycty_51658': 358,\n",
       " 'mycty_51945': 359,\n",
       " 'mycty_51834': 360,\n",
       " 'mycty_51671': 361,\n",
       " 'mycty_51746': 362,\n",
       " 'mycty_51401': 363,\n",
       " 'mycty_51862': 364,\n",
       " 'mycty_51450': 365,\n",
       " 'mycty_51430': 366,\n",
       " 'mycty_51520': 367,\n",
       " 'mycty_51870': 368,\n",
       " 'mycty_51594': 369,\n",
       " 'mycty_51944': 370,\n",
       " 'mycty_51467': 371,\n",
       " 'mycty_52054': 372,\n",
       " 'mycty_51381': 373,\n",
       " 'mycty_51579': 374,\n",
       " 'mycty_51640': 375,\n",
       " 'mycty_51743': 376,\n",
       " 'mycty_51941': 377,\n",
       " 'mycty_51933': 378,\n",
       " 'mycty_51404': 379,\n",
       " 'mycty_51397': 380,\n",
       " 'mycty_51893': 381,\n",
       " 'mycty_51781': 382,\n",
       " 'mycty_51548': 383,\n",
       " 'mycty_51854': 384,\n",
       " 'mycty_51922': 385,\n",
       " 'mycty_51602': 386,\n",
       " 'mycty_52012': 387,\n",
       " 'mycty_51708': 388,\n",
       " 'mycty_52030': 389,\n",
       " 'mycty_51573': 390,\n",
       " 'mycty_51586': 391,\n",
       " 'mycty_51975': 392,\n",
       " 'mycty_51670': 393,\n",
       " 'mycty_51685': 394,\n",
       " 'mycty_51474': 395,\n",
       " 'mycty_51718': 396,\n",
       " 'mycty_51703': 397,\n",
       " 'mycty_51558': 398,\n",
       " 'mycty_52000': 399,\n",
       " 'mycty_51418': 400,\n",
       " 'mycty_51499': 401,\n",
       " 'mycty_51420': 402,\n",
       " 'mycty_51426': 403,\n",
       " 'mycty_51665': 404,\n",
       " 'mycty_51508': 405,\n",
       " 'mycty_51942': 406,\n",
       " 'mycty_51791': 407,\n",
       " 'mycty_51738': 408,\n",
       " 'mycty_51869': 409,\n",
       " 'mycty_51654': 410,\n",
       " 'mycty_51659': 411,\n",
       " 'mycty_51756': 412,\n",
       " 'mycty_51855': 413,\n",
       " 'mycty_52001': 414,\n",
       " 'mycty_51912': 415,\n",
       " 'mycty_51612': 416,\n",
       " 'mycty_51604': 417,\n",
       " 'mycty_51439': 418,\n",
       " 'mycty_51479': 419,\n",
       " 'mycty_51797': 420,\n",
       " 'mycty_51929': 421,\n",
       " 'mycty_51552': 422,\n",
       " 'mycty_51399': 423,\n",
       " 'mycty_51875': 424,\n",
       " 'mycty_51391': 425,\n",
       " 'mycty_51698': 426,\n",
       " 'mycty_51555': 427,\n",
       " 'mycty_51693': 428,\n",
       " 'mycty_51760': 429,\n",
       " 'mycty_51804': 430,\n",
       " 'mycty_51529': 431,\n",
       " 'mycty_51634': 432,\n",
       " 'mycty_51744': 433,\n",
       " 'mycty_51891': 434,\n",
       " 'mycty_51676': 435,\n",
       " 'mycty_51796': 436,\n",
       " 'mycty_51758': 437,\n",
       " 'mycty_52048': 438,\n",
       " 'mycty_51601': 439,\n",
       " 'mycty_51410': 440,\n",
       " 'mycty_51485': 441,\n",
       " 'mycty_51637': 442,\n",
       " 'mycty_52031': 443,\n",
       " 'mycty_51487': 444,\n",
       " 'mycty_51638': 445,\n",
       " 'mycty_51886': 446,\n",
       " 'mycty_51892': 447,\n",
       " 'mycty_51996': 448,\n",
       " 'mycty_51707': 449,\n",
       " 'mycty_51726': 450,\n",
       " 'mycty_51971': 451,\n",
       " 'mycty_51763': 452,\n",
       " 'mycty_51624': 453,\n",
       " 'mycty_51505': 454,\n",
       " 'mycty_51596': 455,\n",
       " 'mycty_51730': 456,\n",
       " 'mycty_51419': 457,\n",
       " 'mycty_51502': 458,\n",
       " 'mycty_51911': 459,\n",
       " 'mycty_51867': 460,\n",
       " 'mycty_51714': 461,\n",
       " 'mycty_51683': 462,\n",
       " 'mycty_51429': 463,\n",
       " 'mycty_51697': 464,\n",
       " 'mycty_51979': 465,\n",
       " 'mycty_51385': 466,\n",
       " 'mycty_51915': 467,\n",
       " 'mycty_51551': 468,\n",
       " 'mycty_51544': 469,\n",
       " 'mycty_51865': 470,\n",
       " 'mycty_51463': 471,\n",
       " 'mycty_51421': 472,\n",
       " 'mycty_51767': 473,\n",
       " 'mycty_51864': 474,\n",
       " 'mycty_51831': 475,\n",
       " 'mycty_51384': 476,\n",
       " 'mycty_51771': 477,\n",
       " 'mycty_51377': 478,\n",
       " 'mycty_51829': 479,\n",
       " 'mycty_51662': 480,\n",
       " 'mycty_51644': 481,\n",
       " 'mycty_51411': 482,\n",
       " 'mycty_51465': 483,\n",
       " 'mycty_51622': 484,\n",
       " 'mycty_51983': 485,\n",
       " 'mycty_51613': 486,\n",
       " 'mycty_51727': 487,\n",
       " 'mycty_51773': 488,\n",
       " 'mycty_52045': 489,\n",
       " 'mycty_51518': 490,\n",
       " 'mycty_51981': 491,\n",
       " 'mycty_51611': 492,\n",
       " 'mycty_51788': 493,\n",
       " 'mycty_51635': 494,\n",
       " 'mycty_51497': 495,\n",
       " 'mycty_51732': 496,\n",
       " 'mycty_51492': 497,\n",
       " 'mycty_51437': 498,\n",
       " 'mycty_51396': 499,\n",
       " 'mycty_51400': 500,\n",
       " 'mycty_51749': 501,\n",
       " 'mycty_51395': 502,\n",
       " 'mycty_51477': 503,\n",
       " 'mycty_51926': 504,\n",
       " 'mycty_51616': 505,\n",
       " 'mycty_51839': 506,\n",
       " 'mycty_51468': 507,\n",
       " 'mycty_51423': 508,\n",
       " 'mycty_52019': 509,\n",
       " 'mycty_51524': 510,\n",
       " 'mycty_51990': 511,\n",
       " 'mycty_51425': 512,\n",
       " 'mycty_51627': 513,\n",
       " 'mycty_51509': 514,\n",
       " 'mycty_51576': 515,\n",
       " 'mycty_51431': 516,\n",
       " 'mycty_51649': 517,\n",
       " 'mycty_51847': 518,\n",
       " 'mycty_51646': 519,\n",
       " 'mycty_51813': 520,\n",
       " 'mycty_51528': 521,\n",
       " 'mycty_51565': 522,\n",
       " 'mycty_51995': 523,\n",
       " 'mycty_51542': 524,\n",
       " 'mycty_52003': 525,\n",
       " 'mycty_51571': 526,\n",
       " 'mycty_51921': 527,\n",
       " 'mycty_51880': 528,\n",
       " 'mycty_51545': 529,\n",
       " 'mycty_51557': 530,\n",
       " 'mycty_51963': 531,\n",
       " 'mycty_52002': 532,\n",
       " 'mycty_51970': 533,\n",
       " 'mycty_51901': 534,\n",
       " 'mycty_51925': 535,\n",
       " 'mycty_51986': 536,\n",
       " 'mycty_51554': 537,\n",
       " 'mysta_17914': 538,\n",
       " 'mycty_51977': 539,\n",
       " 'mycty_51403': 540,\n",
       " 'mycty_52050': 541,\n",
       " 'mycty_51994': 542,\n",
       " 'mycty_51852': 543,\n",
       " 'mycty_51766': 544,\n",
       " 'mycty_51550': 545,\n",
       " 'mycty_51705': 546,\n",
       " 'mycty_51733': 547,\n",
       " 'mycty_52016': 548,\n",
       " 'mycty_51438': 549,\n",
       " 'mycty_51525': 550,\n",
       " 'mycty_51595': 551,\n",
       " 'mycty_51832': 552,\n",
       " 'mycty_51609': 553,\n",
       " 'mycty_51583': 554,\n",
       " 'mycty_51904': 555,\n",
       " 'mycty_51504': 556,\n",
       " 'mycty_51501': 557,\n",
       " 'mycty_52018': 558,\n",
       " 'mycty_51566': 559,\n",
       " 'mycty_51934': 560,\n",
       " 'mycty_51895': 561,\n",
       " 'mycty_51920': 562,\n",
       " 'mycty_51398': 563,\n",
       " 'mycty_51810': 564,\n",
       " 'mycty_51687': 565,\n",
       " 'mycty_51413': 566,\n",
       " 'mycty_51424': 567,\n",
       " 'mycty_51434': 568,\n",
       " 'mycty_51444': 569,\n",
       " 'mycty_51445': 570,\n",
       " 'mycty_51447': 571,\n",
       " 'mycty_51506': 572,\n",
       " 'mycty_51516': 573,\n",
       " 'mycty_51521': 574,\n",
       " 'mycty_51536': 575,\n",
       " 'mycty_51553': 576,\n",
       " 'mycty_51561': 577,\n",
       " 'mycty_51590': 578,\n",
       " 'mycty_51591': 579,\n",
       " 'mycty_51593': 580,\n",
       " 'mycty_51598': 581,\n",
       " 'mycty_51608': 582,\n",
       " 'mycty_51610': 583,\n",
       " 'mycty_51615': 584,\n",
       " 'mycty_51625': 585,\n",
       " 'mycty_51628': 586,\n",
       " 'mycty_51630': 587,\n",
       " 'mycty_51686': 588,\n",
       " 'mycty_51689': 589,\n",
       " 'mycty_51720': 590,\n",
       " 'mycty_51722': 591,\n",
       " 'mycty_51739': 592,\n",
       " 'mycty_51742': 593,\n",
       " 'mycty_51757': 594,\n",
       " 'mycty_51772': 595,\n",
       " 'mycty_51779': 596,\n",
       " 'mycty_51782': 597,\n",
       " 'mycty_51792': 598,\n",
       " 'mycty_51798': 599,\n",
       " 'mycty_51833': 600,\n",
       " 'mycty_51842': 601,\n",
       " 'mycty_51863': 602,\n",
       " 'mycty_51866': 603,\n",
       " 'mycty_51874': 604,\n",
       " 'mycty_51890': 605,\n",
       " 'mycty_51897': 606,\n",
       " 'mycty_51903': 607,\n",
       " 'mycty_51907': 608,\n",
       " 'mycty_51909': 609,\n",
       " 'mycty_51918': 610,\n",
       " 'mycty_51936': 611,\n",
       " 'mycty_51946': 612,\n",
       " 'mycty_51949': 613,\n",
       " 'mycty_51978': 614,\n",
       " 'mycty_51991': 615,\n",
       " 'mycty_51993': 616,\n",
       " 'mycty_51998': 617,\n",
       " 'mycty_52004': 618,\n",
       " 'mycty_52023': 619,\n",
       " 'mycty_52024': 620,\n",
       " 'mycty_52025': 621,\n",
       " 'mycty_52042': 622,\n",
       " 'mycty_52051': 623,\n",
       " 'mycty_52056': 624,\n",
       " 'mysta_12358': 625,\n",
       " 'mysta_13093': 626,\n",
       " 'mysta_22750': 627}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "998dfae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 628\n",
    "torch.manual_seed(1368)\n",
    "\n",
    "shuffle = True\n",
    "embedding_dims = 128\n",
    "epochs = 3\n",
    "initial_lr = 0.025\n",
    "batch_size = 16\n",
    "n_workers = 16\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1fa80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_size, emb_dim):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.center_embeddings = nn.Embedding(emb_size, emb_dim, sparse=True)\n",
    "        self.context_embeddings = nn.Embedding(emb_size, emb_dim, sparse=True)\n",
    "        self.init_emb()\n",
    "\n",
    "    def init_emb(self):\n",
    "        \"\"\"\n",
    "        Init embeddings like word2vec\n",
    "        Center embeddings have uniform distribution in [-0.5/emb_dim , 0.5/emb_dim].\n",
    "        Context embeddings are initialized with 0s.\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        emb_range = 0.5 / self.emb_dim\n",
    "\n",
    "        # Initializing embeddings:\n",
    "        # https://stackoverflow.com/questions/55276504/different-methods-for-initializing-embedding-layer-weights-in-pytorch\n",
    "        self.center_embeddings.weight.data.uniform_(-emb_range, emb_range)\n",
    "        self.context_embeddings.weight.data.uniform_(0, 0)\n",
    "\n",
    "    def forward(self, center, context, neg_context):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            center: List of center words\n",
    "            context: List of context words\n",
    "            neg_context: List of list of negative context words\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # Calculate positive score\n",
    "        emb_center = self.center_embeddings(center)  # Get embeddings for center word\n",
    "        emb_context = self.context_embeddings(context)  # Get embeddings for context word\n",
    "        emb_neg_context = self.context_embeddings(neg_context)  # Get embeddings for negative context words\n",
    "\n",
    "        # Next two lines equivalent to torch.dot(emb_center, emb_context) but for batch\n",
    "        score = torch.mul(emb_center, emb_context)  # Get dot product (part 1)\n",
    "        score = torch.sum(score, dim=1)  # Get dot product (part2)\n",
    "        score = torch.clamp(score, max=10, min=-10)\n",
    "        score = -F.logsigmoid(score)  # Get score for the positive pairs\n",
    "\n",
    "        # Calculate negative score (for negative samples)\n",
    "        neg_score = torch.bmm(emb_neg_context, emb_center.unsqueeze(2)).squeeze()  # Get dot product\n",
    "        neg_score = torch.clamp(neg_score, max=10, min=-10)\n",
    "        neg_score = -torch.sum(F.logsigmoid(-neg_score), dim=-1)\n",
    "\n",
    "        # Return combined score\n",
    "        return torch.mean(score + neg_score)\n",
    "\n",
    "    def get_center_emb(self, center):\n",
    "        return self.center_embeddings(center)\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        return self.center_embeddings.weight.cpu().data.numpy()\n",
    "\n",
    "    def save_embeddings(self, file_name):\n",
    "        embedding = self.center_embeddings.weight.cpu().data.numpy()\n",
    "        np.save(file_name, embedding)\n",
    "\n",
    "\n",
    "class Sequences:\n",
    "    NEGATIVE_SAMPLE_TABLE_SIZE = 1e7\n",
    "    WINDOW = 5\n",
    "    \n",
    "    def __init__(self, seq_list, vocab_dict, subsample: float = 0.001, power: float = 0.75):\n",
    "        \"\"\"\n",
    "        Initializes a Sequences object for use in a Dataset.\n",
    "        Args:\n",
    "            seq_list: rows of sequences (2d array) - global location ID\n",
    "            vocab_dict: all locations details in dict format\n",
    "            subsample: Subsampling parameter; suggested range (0, 1e-5)\n",
    "            power: Negative sampling parameter; suggested 0.75\n",
    "        \"\"\"\n",
    "        self.negative_idx = 0\n",
    "        self.n_unique_tokens = 0\n",
    "        \n",
    "        # Load sequences list\n",
    "        self.sequences_raw = seq_list\n",
    "        self.n_sequences = len(self.sequences_raw)\n",
    "        print('Sequences loaded (length = {:,})'.format(self.n_sequences))\n",
    "        \n",
    "        self.loc_freq = self.get_loc_freq()\n",
    "        print('Location frequency calculated')\n",
    "        \n",
    "        # Load vocab dict\n",
    "        self.vocab_dict = vocab_dict\n",
    "        self.loc2id, self.id2loc = self.get_mapping_dicts()\n",
    "        self.n_unique_tokens = len(self.loc2id)\n",
    "        print('No. of unique tokens: {}'.format(self.n_unique_tokens))\n",
    "#         save_model(self.loc2id, '{}/loc2id'.format(MODEL_PATH))\n",
    "#         save_model(self.id2loc, '{}/id2loc'.format(MODEL_PATH))\n",
    "        print('Loc2Id and Id2Loc created and saved')\n",
    "        \n",
    "        self.sequences = self.convert_sequence_to_id()\n",
    "        self.loc_freq = self.convert_loc_freq_to_id()\n",
    "        print('Convert sequence and location freq to ID')\n",
    "        \n",
    "        self.discard_probs = self.get_discard_probs(sample=subsample)\n",
    "        print('Discard probability calculated')\n",
    "\n",
    "        self.neg_table = self.get_negative_sample_table(power=power)\n",
    "        print('Negative sample table created')\n",
    "    \n",
    "    def get_mapping_dicts(self):\n",
    "        loc2id = {w: idx for (idx, w) in enumerate(self.vocab_dict)}\n",
    "        id2loc = {idx: w for (idx, w) in enumerate(self.vocab_dict)}\n",
    "        return loc2id, id2loc\n",
    "    \n",
    "    def get_loc_freq(self) -> Counter:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of location frequencies.\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # Flatten list\n",
    "        seq_flat = list(itertools.chain.from_iterable(self.sequences_raw))\n",
    "\n",
    "        # Get word frequency\n",
    "        loc_freq = Counter(seq_flat)\n",
    "        return loc_freq\n",
    "    \n",
    "    def convert_sequence_to_id(self):\n",
    "        vfunc = np.vectorize(lambda x: self.get_list_location_id(x))\n",
    "        return vfunc(self.sequences_raw)\n",
    "\n",
    "    def get_list_location_id(self, x):\n",
    "        return np.array([self.get_location_id(i) for i in x], dtype=object)\n",
    "\n",
    "    def get_location_id(self, x):\n",
    "        return self.loc2id.get(x, -1)\n",
    "\n",
    "    def convert_loc_freq_to_id(self):\n",
    "        return {self.loc2id[k]: v for k, v in self.loc_freq.items()}\n",
    "    \n",
    "    def get_discard_probs(self, sample=0.001) -> Dict[int, float]:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of locations and their associated discard probability, where the location should be discarded\n",
    "        if np.random.rand() < probability.\n",
    "        Args:\n",
    "            sample: \n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # Convert to array\n",
    "        loc_freq = np.array(list(self.loc_freq.items()), dtype=np.float64)\n",
    "\n",
    "        # Convert to probabilities\n",
    "        loc_freq[:, 1] = loc_freq[:, 1] / loc_freq[:, 1].sum()\n",
    "\n",
    "        # Perform subsampling\n",
    "        # http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\n",
    "        loc_freq[:, 1] = (np.sqrt(loc_freq[:, 1] / sample) + 1) * (sample / loc_freq[:, 1])\n",
    "\n",
    "        # Get dict\n",
    "        discard_probs = {int(k): v for k, v in loc_freq.tolist()}\n",
    "        return discard_probs\n",
    "\n",
    "    def get_negative_sample_table(self, power=0.75) -> np.array:\n",
    "        \"\"\"\n",
    "        Returns a table (size = NEGATIVE_SAMPLE_TABLE_SIZE) of negative samples which can be selected via indexing.\n",
    "        Args:\n",
    "            power:\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # Convert to array\n",
    "        loc_freq = np.array(list(self.loc_freq.items()), dtype=np.float64)\n",
    "\n",
    "        # Adjust by power\n",
    "        loc_freq[:, 1] = loc_freq[:, 1] ** power\n",
    "\n",
    "        # Get probabilities\n",
    "        loc_freq_sum = loc_freq[:, 1].sum()\n",
    "        loc_freq[:, 1] = loc_freq[:, 1] / loc_freq_sum\n",
    "\n",
    "        # Multiply probabilities by sample table size\n",
    "        loc_freq[:, 1] = np.round(loc_freq[:, 1] * self.NEGATIVE_SAMPLE_TABLE_SIZE)\n",
    "\n",
    "        # Convert to int\n",
    "        loc_freq = loc_freq.astype(int).tolist()\n",
    "\n",
    "        # Create sample table\n",
    "        sample_table = [[tup[0]] * tup[1] for tup in loc_freq]\n",
    "        sample_table = np.array(list(itertools.chain.from_iterable(sample_table)))\n",
    "        np.random.shuffle(sample_table)\n",
    "        return sample_table\n",
    "    \n",
    "    # Works on per sequence\n",
    "    def get_pairs(self, idx, window=5):\n",
    "        pairs = []\n",
    "        sequence = self.sequences[idx]\n",
    "\n",
    "        for center_idx, node in enumerate(sequence):\n",
    "            for i in range(-window, window + 1):\n",
    "                context_idx = center_idx + i\n",
    "                if context_idx > 0 and context_idx < len(sequence) and node != sequence[\n",
    "                    context_idx] and np.random.rand() < self.discard_probs[sequence[context_idx]]:\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "\n",
    "        return pairs\n",
    "    \n",
    "    def get_negative_samples(self, context, sample_size=5) -> np.array:\n",
    "        \"\"\"\n",
    "        Returns a list of negative samples, where len = sample_size.\n",
    "        Args:\n",
    "            sample_size:\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Get a batch from the shuffled table\n",
    "            neg_sample = self.neg_table[self.negative_idx:self.negative_idx + sample_size]\n",
    "\n",
    "            # Update negative index\n",
    "            self.negative_idx = (self.negative_idx + sample_size) % len(self.neg_table)\n",
    "\n",
    "            # Check if batch insufficient\n",
    "            if len(neg_sample) != sample_size:\n",
    "                neg_sample = np.concatenate((neg_sample, self.neg_table[:self.negative_idx]))\n",
    "\n",
    "            # Check if context in negative sample\n",
    "            if not context in neg_sample:\n",
    "                return neg_sample\n",
    "\n",
    "\n",
    "class SequencesDataset(Dataset):\n",
    "    def __init__(self, sequences: Sequences, neg_sample_size=5):\n",
    "        self.sequences = sequences\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sequences.n_sequences\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pairs = self.sequences.get_pairs(idx)\n",
    "        neg_samples = []\n",
    "        for center, context in pairs:\n",
    "            neg_samples.append(self.sequences.get_negative_samples(context))\n",
    "\n",
    "        return pairs, neg_samples\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(batches):\n",
    "        # logger.info('Batches: {}'.format(batches))\n",
    "        pairs_batch = [batch[0] for batch in batches]\n",
    "        neg_contexts_batch = [batch[1] for batch in batches]\n",
    "\n",
    "        pairs_batch = list(itertools.chain.from_iterable(pairs_batch))\n",
    "        neg_contexts = list(itertools.chain.from_iterable(neg_contexts_batch))\n",
    "\n",
    "        centers = [center for center, _ in pairs_batch]\n",
    "        contexts = [context for _, context in pairs_batch]\n",
    "        return torch.LongTensor(centers), torch.LongTensor(contexts), torch.LongTensor(neg_contexts)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_for_mf(batches):\n",
    "        batch_list = []\n",
    "\n",
    "        for batch in batches:\n",
    "            pairs = np.array(batch[0])\n",
    "            negs = np.array(batch[1])\n",
    "            negs = np.vstack((pairs[:, 0].repeat(negs.shape[1]), negs.ravel())).T\n",
    "\n",
    "            pairs_arr = np.ones((pairs.shape[0], pairs.shape[1] + 1), dtype=int)\n",
    "            pairs_arr[:, :-1] = pairs\n",
    "\n",
    "            negs_arr = np.zeros((negs.shape[0], negs.shape[1] + 1), dtype=int)\n",
    "            negs_arr[:, :-1] = negs\n",
    "\n",
    "            all_arr = np.vstack((pairs_arr, negs_arr))\n",
    "            batch_list.append(all_arr)\n",
    "\n",
    "        batch_array = np.vstack(batch_list)\n",
    "        # np.random.shuffle(batch_array)\n",
    "\n",
    "        # Return item1, item2, label\n",
    "        return (torch.LongTensor(batch_array[:, 0]), torch.LongTensor(batch_array[:, 1]),\n",
    "                torch.FloatTensor(batch_array[:, 2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a0cc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences loaded (length = 37,904)\n",
      "Location frequency calculated\n",
      "No. of unique tokens: 628\n",
      "Loc2Id and Id2Loc created and saved\n",
      "Convert sequence and location freq to ID\n",
      "Discard probability calculated\n",
      "Negative sample table created\n"
     ]
    }
   ],
   "source": [
    "# Load dataloader\n",
    "sequences = Sequences(seq_list=list_seq, vocab_dict=dict_loc)\n",
    "dataset = SequencesDataset(sequences)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=shuffle, \n",
    "                        # num_workers=n_workers, \n",
    "                        collate_fn=dataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d10ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "skipgram = SkipGram(vocab_size, embedding_dims).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac78d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:11<00:23, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.7550, Lr: 0.000000\n",
      "Model state dict saved to chkpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:22<00:11, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 2.0075, Lr: 0.000000\n",
      "Model state dict saved to chkpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:34<00:00, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.9007, Lr: 0.000000\n",
      "Model state dict saved to chkpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "optimizer = optim.SparseAdam(list(skipgram.parameters()), lr=initial_lr)\n",
    "\n",
    "results = []\n",
    "start_time = datetime.datetime.now()\n",
    "for epoch in tqdm(range(epochs), total=epochs, position=0, leave=True):\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(dataloader))\n",
    "    running_loss = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for i, batches in enumerate(dataloader):\n",
    "        centers = batches[0].to(device)\n",
    "        contexts = batches[1].to(device)\n",
    "        neg_contexts = batches[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = skipgram.forward(centers, contexts, neg_contexts)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
    "        \n",
    "    print(\"Epoch: {}, Loss: {:.4f}, Lr: {:.6f}\".format(epoch, running_loss, optimizer.param_groups[0]['lr']))\n",
    "    results.append([epoch, i, running_loss])\n",
    "    running_loss = 0\n",
    "\n",
    "    # save model\n",
    "    current_datetime = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')\n",
    "#     state_dict_path = '{}/skipgram_epoch_{}_{}.pt'.format(MODEL_PATH, epoch, current_datetime)\n",
    "    # state_dict_path=\"/Users/md.kamal/work-code-sample/location-recommendation/notebooks/all-model-state.pt\"\n",
    "    # state_dict_path =f\"{data_path}/all-model-state.pt\"\n",
    "    checkpoint = { \"epoch\": epoch,\n",
    "                  \"model_state\": skipgram.state_dict(),\n",
    "                  \"optim_state\": optimizer.state_dict(),\n",
    "                  \"loc2idx\": loc2idx,\n",
    "                  \"idx2loc\": idx2loc\n",
    "                  \n",
    "    }\n",
    "    torch.save(checkpoint, 'chkpt')\n",
    "#     torch.save(skipgram.state_dict(), state_dict_path)\n",
    "    print('Model state dict saved to {}'.format('chkpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f21983",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "time_diff = round((end_time - start_time).total_seconds() / 60, 2)\n",
    "print('Total time taken: {:,} minutes'.format(time_diff))\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    torch.save(skipgram.cpu().state_dict(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
